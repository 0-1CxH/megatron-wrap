__inherit__: llama-moe-base.yaml

num_layers: 28
hidden_size: 2560
num_attn_heads: 20
num_key_value_heads: 20
num-query-groups: 1
group_query_attention: true

ffn_hidden_size: 13568
moe_ffn_dim: 1664
max_position_embedding: 4096
rotary_base: 10000

num_experts: 64
moe_router_topk: 6
# num_shared_experts: 2
# topk_amp_factor: 1

norm_epsilon: 1e-06

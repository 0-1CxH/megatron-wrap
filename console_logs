[32m2024-12-20 08:09:00[0m [1mINFO    [0m[34mwrap.py:initialize:25                   [0m [1m[STATUS] initialization started[0m
[32m2024-12-20 08:09:07[0m [1mINFO    [0m[34mwrap.py:<lambda>:68                     [0m [1m
---------------------------- megatron-lm arguments ----------------------------
accumulate_allreduce_grads_in_fp32 ......................................... False
adam_beta1 ................................................................... 0.9
adam_beta2 .................................................................. 0.95
adam_eps ................................................................... 1e-08
add_bias_linear ............................................................ False
add_position_embedding ..................................................... False
add_qkv_bias ............................................................... False
adlr_autoresume ............................................................ False
adlr_autoresume_interval .................................................... 1000
app_tag_run_name ............................................................ None
app_tag_run_version ........................................................ 0.0.0
apply_layernorm_1p ......................................................... False
apply_query_key_layer_scaling .............................................. False
apply_residual_connection_post_layernorm ................................... False
apply_rope_fusion ........................................................... True
async_save .................................................................. None
async_tensor_model_parallel_allreduce ....................................... True
attention_dropout ............................................................ 0.0
attention_softmax_in_fp32 ................................................... True
auto_detect_ckpt_format .................................................... False
barrier_with_L1_time ........................................................ True
batch_size .................................................................. None
bert_binary_head ............................................................ True
bert_embedder_type ...................................................... megatron
bert_load ................................................................... None
bf16 ........................................................................ True
bias_activation_fusion ..................................................... False
bias_dropout_fusion ......................................................... True
bias_gelu_fusion ............................................................ True
bias_swiglu_fusion .......................................................... True
biencoder_projection_dim ....................................................... 0
biencoder_shared_query_context_model ....................................... False
block_data_path ............................................................. None
calculate_per_token_loss ................................................... False
check_for_nan_in_loss_and_grad .............................................. True
check_weight_hash_across_dp_replicas_interval ............................... None
checkpoint_activations ...................................................... None
ckpt_assume_constant_structure ............................................. False
ckpt_fully_parallel_load ................................................... False
ckpt_fully_parallel_save .................................................... True
ckpt_fully_parallel_save_deprecated ........................................ False
ckpt_step ................................................................... None
classes_fraction ............................................................. 1.0
clip_grad .................................................................... 1.0
clone_scatter_output_in_embedding ........................................... True
consumed_train_samples ......................................................... 0
consumed_valid_samples ......................................................... 0
context_parallel_size .......................................................... 1
create_attention_mask_in_dataloader ......................................... True
cross_entropy_loss_fusion .................................................. False
data_cache_path ............................................................. None
data_parallel_random_init .................................................. False
data_parallel_size .......................................................... None
data_path ................................................................... None
data_per_class_fraction ...................................................... 1.0
data_sharding ............................................................... True
dataloader_type ........................................................... cyclic
ddp_average_in_collective .................................................. False
ddp_bucket_size ............................................................. None
decoder_num_layers .......................................................... None
decoder_seq_length .......................................................... None
decoupled_lr ................................................................ None
decoupled_min_lr ............................................................ None
defer_embedding_wgrad_compute .............................................. False
delay_grad_reduce ........................................................... True
delay_param_gather ......................................................... False
deterministic_mode ......................................................... False
dino_bottleneck_size ......................................................... 256
dino_freeze_last_layer ......................................................... 1
dino_head_hidden_size ....................................................... 2048
dino_local_crops_number ....................................................... 10
dino_local_img_size ........................................................... 96
dino_norm_last_layer ....................................................... False
dino_teacher_temp ........................................................... 0.07
dino_warmup_teacher_temp .................................................... 0.04
dino_warmup_teacher_temp_epochs ............................................... 30
disable_straggler_on_startup ............................................... False
dist_ckpt_format ...................................................... torch_dist
dist_ckpt_strictness ........................................ assume_ok_unexpected
distribute_saved_activations ............................................... False
distributed_backend ......................................................... nccl
distributed_timeout_minutes ................................................... 60
embedding_path .............................................................. None
empty_unused_memory_level ...................................................... 0
enable_one_logger ........................................................... True
encoder_num_layers .......................................................... None
encoder_seq_length .......................................................... None
end_weight_decay ............................................................ None
eod_mask_loss .............................................................. False
eval_interval ............................................................... None
eval_iters .................................................................. None
evidence_data_path .......................................................... None
exit_duration_in_mins ....................................................... None
exit_interval ............................................................... None
exit_on_missing_checkpoint .................................................. True
exit_signal_handler ........................................................ False
expert_model_parallel_size ..................................................... 1
ffn_hidden_size ............................................................ 11008
finetune .................................................................... True
fp16 ....................................................................... False
fp16_lm_cross_entropy ...................................................... False
fp32_residual_connection ................................................... False
fp8 ......................................................................... None
fp8_amax_compute_algo ........................................................ max
fp8_amax_history_len ........................................................ 1024
fp8_interval ................................................................... 1
fp8_margin ..................................................................... 0
fp8_wgrad ................................................................... True
gated_linear_unit .......................................................... False
global_batch_size ............................................................ 128
gradient_accumulation_fusion ................................................ True
group_query_attention ...................................................... False
head_lr_mult ................................................................. 1.0
hidden_dropout ............................................................... 0.0
hidden_size ................................................................. 4096
hybrid_attention_ratio ....................................................... 0.0
hybrid_mlp_ratio ............................................................. 0.0
hybrid_override_pattern ..................................................... None
hysteresis ..................................................................... 2
ict_head_size ............................................................... None
ict_load .................................................................... None
img_h ........................................................................ 224
img_w ........................................................................ 224
indexer_batch_size ........................................................... 128
indexer_log_interval ........................................................ 1000
inference_batch_times_seqlen_threshold ....................................... 512
init_method_std ............................................................ 0.006
init_method_xavier_uniform ................................................. False
initial_loss_scale .................................................... 4294967296
iter_per_epoch .............................................................. 1250
kv_channels ................................................................. None
lazy_mpu_init ............................................................... None
load ................................................ ckpt/llama-2-7b-mcore-tp4pp1
local_rank ..................................................................... 0
log_batch_size_to_tensorboard ............................................... True
log_interval ................................................................... 1
log_learning_rate_to_tensorboard ............................................ True
log_loss_scale_to_tensorboard ............................................... True
log_memory_to_tensorboard .................................................. False
log_num_zeros_in_grad ....................................................... True
log_params_norm ............................................................. True
log_progress ............................................................... False
log_straggler .............................................................. False
log_throughput .............................................................. True
log_timers_to_tensorboard ................................................... True
log_validation_ppl_to_tensorboard .......................................... False
log_world_size_to_tensorboard .............................................. False
logging_level ............................................................... None
loss_scale .................................................................. None
loss_scale_window ........................................................... 1000
lr ......................................................................... 2e-05
lr_decay_iters .............................................................. None
lr_decay_samples ............................................................ None
lr_decay_style ............................................................ cosine
lr_warmup_fraction .......................................................... 0.05
lr_warmup_init ............................................................... 0.0
lr_warmup_iters ................................................................ 0
lr_warmup_samples .............................................................. 0
lr_wsd_decay_iters .......................................................... None
lr_wsd_decay_samples ........................................................ None
lr_wsd_decay_style ................................................... exponential
make_vocab_size_divisible_by ................................................. 100
manual_gc .................................................................. False
manual_gc_eval .............................................................. True
manual_gc_interval ............................................................. 0
mask_factor .................................................................. 1.0
mask_prob ................................................................... 0.15
mask_type ................................................................. random
masked_softmax_fusion ...................................................... False
max_position_embeddings ..................................................... 4096
max_tokens_to_oom .......................................................... 12000
merge_file .................................................................. None
micro_batch_size ............................................................... 4
min_loss_scale ............................................................... 1.0
min_lr ....................................................................... 0.0
mmap_bin_files .............................................................. True
mock_data .................................................................. False
model_parallel_size ......................................................... None
moe_aux_loss_coeff ............................................................. 0
moe_expert_capacity_factor .................................................. None
moe_extended_tp ............................................................ False
moe_grouped_gemm ........................................................... False
moe_input_jitter_eps ........................................................ None
moe_layer_recompute ........................................................ False
moe_pad_expert_input_to_capacity ........................................... False
moe_per_layer_logging ...................................................... False
moe_router_load_balancing_type .......................................... aux_loss
moe_router_pre_softmax ..................................................... False
moe_router_topk ................................................................ 2
moe_token_dispatcher_type .............................................. allgather
moe_token_drop_policy ...................................................... probs
moe_z_loss_coeff ............................................................ None
nccl_communicator_config_path ............................................... None
no_load_optim ............................................................... True
no_load_rng ................................................................. True
no_persist_layer_norm ...................................................... False
no_save_optim ............................................................... None
no_save_rng ................................................................. None
no_sync_func ................................................................ None
norm_epsilon ............................................................... 1e-05
normalization ............................................................ RMSNorm
num_attention_heads ........................................................... 32
num_channels ................................................................... 3
num_classes ................................................................. 1000
num_dataset_builder_threads .................................................... 1
num_experts ................................................................. None
num_layers .................................................................... 32
num_layers_per_virtual_pipeline_stage ....................................... None
num_microbatches_with_partial_activation_checkpoints ........................ None
num_moe_experts ............................................................. None
num_query_groups ............................................................ None
num_workers .................................................................... 8
one_logger_async ........................................................... False
one_logger_project ................................................... megatron-lm
one_logger_run_name ......................................................... None
onnx_safe ................................................................... None
openai_gelu ................................................................ False
optimizer ................................................................... adam
output_bert_embeddings ..................................................... False
overlap_grad_reduce ........................................................ False
overlap_p2p_comm ............................................................ True
overlap_param_gather ....................................................... False
override_opt_param_scheduler ................................................ True
padded_vocab_size .......................................................... 32000
param_sync_func ............................................................. None
params_dtype ................................................................ None
patch_dim ..................................................................... 16
perform_initialization ...................................................... True
pipeline_dtype .............................................................. None
pipeline_model_parallel_size ................................................... 1
pipeline_model_parallel_split_rank .......................................... None
position_embedding_type ......................................... learned_absolute
pretrained_checkpoint ....................................................... None
profile .................................................................... False
profile_ranks ................................................................ [0]
profile_step_end .............................................................. 12
profile_step_start ............................................................ 10
qk_layernorm ............................................................... False
query_in_block_prob .......................................................... 0.1
rampup_batch_size ........................................................... None
rank ........................................................................... 0
recompute_activations ...................................................... False
recompute_granularity ....................................................... None
recompute_method ............................................................ None
recompute_num_layers ........................................................ None
reset_attention_mask ....................................................... False
reset_position_ids ......................................................... False
retriever_report_topk_accuracies .............................................. []
retriever_score_scaling .................................................... False
retriever_seq_length ......................................................... 256
retro_add_retriever ........................................................ False
retro_attention_gate ........................................................... 1
retro_cyclic_train_iters .................................................... None
retro_encoder_attention_dropout .............................................. 0.1
retro_encoder_hidden_dropout ................................................. 0.1
retro_encoder_layers ........................................................... 2
retro_num_neighbors ............................................................ 2
retro_num_retrieved_chunks ..................................................... 2
retro_project_dir ........................................................... None
retro_verify_neighbor_count ................................................. True
rotary_base ................................................................ 10000
rotary_interleaved ......................................................... False
rotary_percent ............................................................... 1.0
rotary_seq_len_interpolation_factor ......................................... None
s3_cache_path ............................................................... None
sample_rate .................................................................. 1.0
save ........................................................................ None
save_interval ............................................................... None
scatter_gather_tensors_in_pipeline .......................................... True
seed ........................................................................ 1234
seq_length ................................................................... 512
sequence_parallel ........................................................... True
sgd_momentum ................................................................. 0.9
short_seq_prob ............................................................... 0.1
skip_train ................................................................. False
spec ........................................................................ None
split .................................................................... 100,0,0
squared_relu ............................................................... False
standalone_embedding_stage ................................................. False
start_weight_decay .......................................................... None
straggler_ctrlr_port ....................................................... 65535
straggler_minmax_count ......................................................... 1
swiglu ...................................................................... True
swin_backbone_type .......................................................... tiny
tensor_model_parallel_size ..................................................... 4
tensorboard_dir ............................................................. None
tensorboard_log_interval ....................................................... 1
tensorboard_queue_size ...................................................... 1000
test_data_path .............................................................. None
test_mode .................................................................. False
tiktoken_num_special_tokens ................................................. 1000
tiktoken_pattern ............................................................ None
tiktoken_special_tokens ..................................................... None
timing_log_level ............................................................... 0
timing_log_option ......................................................... minmax
titles_data_path ............................................................ None
tokenizer_model ............................................................. None
tokenizer_type ......................................... GPTSentencePieceTokenizer
tp_comm_bulk_dgrad .......................................................... True
tp_comm_bulk_wgrad .......................................................... True
tp_comm_overlap ............................................................ False
tp_comm_overlap_ag .......................................................... True
tp_comm_overlap_cfg ......................................................... None
tp_comm_overlap_rs .......................................................... True
tp_comm_overlap_rs_dgrad ................................................... False
tp_comm_split_ag ............................................................ True
tp_comm_split_rs ............................................................ True
train_data_path ............................................................. None
train_iters ................................................................... 64
train_samples ............................................................... None
transformer_impl .............................................. transformer_engine
untie_embeddings_and_output_weights ......................................... True
use_checkpoint_args ........................................................ False
use_checkpoint_opt_param_scheduler ......................................... False
use_cpu_initialization ...................................................... None
use_dist_ckpt .............................................................. False
use_distributed_optimizer ................................................... True
use_flash_attn .............................................................. True
use_legacy_models .......................................................... False
use_one_sent_docs .......................................................... False
use_ring_exchange_p2p ...................................................... False
use_rotary_position_embeddings .............................................. True
use_tp_pp_dp_mapping ....................................................... False
valid_data_path ............................................................. None
variable_seq_lengths ....................................................... False
virtual_pipeline_model_parallel_size ........................................ None
vision_backbone_type ......................................................... vit
vision_pretraining ......................................................... False
vision_pretraining_type ................................................. classify
vocab_extra_ids ................................................................ 0
vocab_file .................................................................. None
vocab_size ................................................................. 32000
wandb_exp_name .............................................................. None
wandb_project ............................................................... None
wandb_save_dir .............................................................. None
warmup ...................................................................... None
weight_decay ................................................................. 0.0
weight_decay_incr_style ................................................. constant
wgrad_deferral_limit ........................................................... 0
world_size ..................................................................... 8
yaml_cfg .................................................................... None
--------------------------------------------------------------------------------
[0m
[rank4]:[W1220 20:09:08.761777504 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank0]:[W1220 20:09:08.765558944 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank5]:[W1220 20:09:08.830617228 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank1]:[W1220 20:09:08.830691362 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank6]:[W1220 20:09:08.088651301 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank2]:[W1220 20:09:08.090953939 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank7]:[W1220 20:09:08.092374306 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[rank3]:[W1220 20:09:08.094682331 init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank7/8) [STATUS] initialization finished, parallel state of this rank: (TP3/4 PP0/1 DP1/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank4/8) [STATUS] initialization finished, parallel state of this rank: (TP0/4 PP0/1 DP1/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank1/8) [STATUS] initialization finished, parallel state of this rank: (TP1/4 PP0/1 DP0/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank5/8) [STATUS] initialization finished, parallel state of this rank: (TP1/4 PP0/1 DP1/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank0/8) [STATUS] initialization finished, parallel state of this rank: (TP0/4 PP0/1 DP0/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mmodel.py:_model_:29                     [0m [1m[STATUS] building model[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank3/8) [STATUS] initialization finished, parallel state of this rank: (TP3/4 PP0/1 DP0/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank2/8) [STATUS] initialization finished, parallel state of this rank: (TP2/4 PP0/1 DP0/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:10[0m [1mINFO    [0m[34mwrap.py:initialize:31                   [0m [1m(rank6/8) [STATUS] initialization finished, parallel state of this rank: (TP2/4 PP0/1 DP1/2 CP0/1 EP0/1)[0m
[32m2024-12-20 08:09:29[0m [1mINFO    [0m[34mwrap.py:setup_model_and_optimizer:192   [0m [1m[STATUS] model is sucessfully built[0m
[32m2024-12-20 08:09:29[0m [1mINFO    [0m[34mwrap.py:setup_model_and_optimizer:205   [0m [1m[STATUS] optimizer is sucessfully built DistributedOptimizer(type=adam, lr=2e-05, min_lr=0.0, weight_decay=0.0adam_beta=(0.9,0.95), adam_eps=1e-08, sgd_momentum=0.9[0m
[32m2024-12-20 08:09:29[0m [1mINFO    [0m[34mwrap.py:setup_model_and_optimizer:206   [0m [1m[STATUS] scheduler is sucessfully built OptimizerParamScheduler(lr_decay_style=cosine, lr_warmup_steps=409.6, lr_decay_steps=8192)[0m
[rank2]:[W1220 20:09:29.483059828 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank0]:[W1220 20:09:29.483539005 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank3]:[W1220 20:09:29.520029794 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank1]:[W1220 20:09:29.532838001 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank6]:[W1220 20:09:29.537843969 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank4]:[W1220 20:09:29.544493134 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank5]:[W1220 20:09:29.555438619 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[rank7]:[W1220 20:09:29.602875045 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
